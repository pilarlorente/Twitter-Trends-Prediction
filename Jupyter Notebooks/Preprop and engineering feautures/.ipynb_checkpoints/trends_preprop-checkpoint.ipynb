{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(string):\n",
    "    \"\"\"Transforma una cadena de caracteres con forma de diccionario a diccionario\"\"\"\n",
    "    if string != \"[]\":\n",
    "        string = json.loads(string.replace(\"'\", \"\\\"\"))\n",
    "        return \",\".join([s[\"screen_name\"] for s in string])\n",
    "    return \"\"\n",
    "\n",
    "def to_list(list_):\n",
    "    \"\"\"Transforma una cadena de caracteres con forma de lista a lista\"\"\"\n",
    "    if list_ != \"[]\":\n",
    "        list_ = list_[1:-1]\n",
    "        list_ = list_.split(\",\")\n",
    "        return \",\".join([s.strip().strip(\"'\") for s in list_])\n",
    "    return \"\"\n",
    "\n",
    "def normalize(s):\n",
    "    \"\"\"Reemplaza las letras con tildes y retorna la cadena de caracteres en minuscula\"\"\"\n",
    "    replacements = ((\"á\", \"a\"), (\"é\", \"e\"), (\"í\", \"i\"), (\"ó\", \"o\"), (\"ú\", \"u\"))\n",
    "    for a, b in replacements:\n",
    "        s = s.lower()\n",
    "        s = s.replace(a, b)\n",
    "    return s\n",
    "\n",
    "def deEmojify(text):\n",
    "    \"\"\"Quita los emojis de los tweets\"\"\"\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r\"\", text)\n",
    "\n",
    "def cleanTxt(text):\n",
    "    \"\"\"Elimina mentions, hiperlinks, quita el simbolo \"#\" y el \"RT\"\"\"\"\n",
    "    text = re.sub(r\"@[a-zA-Z0-9]+\", \"\", text) #Removes @mentions\n",
    "    text = re.sub(r\"#\", \"\", text) #Removing the \"#\" symbol\n",
    "    text = re.sub(r\"RT[\\s]+\", \"\", text) #Removing RT\n",
    "    text = re.sub(r\"https?:\\/\\/\\S+\", \"\", text) #Remove the hyperlink\n",
    "    return text\n",
    "\n",
    "def replace_punct(s):\n",
    "    \"\"\"Elimina los signos de puntuacion\"\"\"\n",
    "    for i in string.punctuation:\n",
    "        if i in s:\n",
    "            s = s.replace(i, \"\").strip()\n",
    "    return s\n",
    "\n",
    "def replace_num(s):\n",
    "    \"\"\"Remueve los numeros de los tweets\"\"\"\n",
    "    for i in [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]:\n",
    "        s = s.replace(i, \"\")\n",
    "    return s\n",
    "\n",
    "def tokenizador(text):\n",
    "    \"\"\"Tokeniza el texto del tweet\"\"\"\n",
    "    important_words = []\n",
    "    for word in text.split(\" \"):\n",
    "        if word not in stopwords.words(\"spanish\"):\n",
    "            if word != \"\":\n",
    "                important_words.append(word)\n",
    "    return \" \".join(important_words).strip()\n",
    "\n",
    "def foo(text):\n",
    "    \"\"\"Elimina mas signos de puntuacion\"\"\"\n",
    "    forbidden = (\"?\", \"¿\", \"¡\", \"!\", \",\", \".\", \";\", \":\", \"-\", \"'\", \"+\", \"$\", \"/\", \"*\",'«','»', \"~\", \"(\", \")\")\n",
    "    aux = \"\"\n",
    "    for v in text:\n",
    "        if not v in forbidden:\n",
    "            aux += v\n",
    "    return aux\n",
    "\n",
    "def quita_palabras_pequeñas(text):\n",
    "    \"\"\"Quita palabras de longitud menor a 3 del texto del tweet\"\"\"\n",
    "    return \" \".join([word for word in text.split(\" \") if len(word) > 2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"C:/Users/Daniel/Desktop/csv/dia 24/trends/tweets_tendencias_24.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hace drop a las columnas de ids, husos horarios, url y traducciones\n",
    "# 2. Filtra los tweets por idioma (\"es\")\n",
    "\n",
    "columns_to_drop = [\"conversation_id\", \"cashtags\", \"timezone\", \"user_id\", \"name\", \"near\", \"geo\", \"source\",\n",
    "                   \"user_rt_id\", \"user_rt\", \"retweet_id\", \"retweet_date\", \"translate\", \"trans_src\",\n",
    "                   \"trans_dest\", \"place\", \"quote_url\", \"thumbnail\", \"created_at\", \"id\", \"link\"]\n",
    "\n",
    "df.drop(columns_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df = df[df.language == \"es\"]\n",
    "\n",
    "df.drop(\"language\", axis = 1, inplace = True)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma la columna \"reply_to\" a diccionario\n",
    "# Elimina las filas donde no es posible\n",
    "\n",
    "reply_to_rows = []\n",
    "for num, row in enumerate(df.reply_to):\n",
    "    try:\n",
    "        to_dict(row)\n",
    "    except:\n",
    "        reply_to_rows.append(num)\n",
    "        \n",
    "df.drop(reply_to_rows, inplace = True)\n",
    "\n",
    "df.reply_to = df.reply_to.apply(to_dict)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma la columna \"mentions\" a diccionario\n",
    "# Elimina las filas donde no es posible\n",
    "\n",
    "mention_rows = []\n",
    "for num, row in enumerate(df.mentions):\n",
    "    try:\n",
    "        to_dict(row)\n",
    "    except:\n",
    "        mention_rows.append(num)\n",
    "        \n",
    "df.drop(mention_rows, inplace = True)\n",
    "\n",
    "df.mentions = df.mentions.apply(to_dict)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma la columna \"hashtags\" a lista\n",
    "# Elimina las filas donde no es posible\n",
    "\n",
    "hashtags_rows = []\n",
    "for num, row in enumerate(df.hashtags):\n",
    "    try:\n",
    "        to_list(row)\n",
    "    except:\n",
    "        hashtags_rows.append(num)\n",
    "        \n",
    "df.drop(hashtags_rows, inplace = True)\n",
    "\n",
    "df.hashtags = df.hashtags.apply(to_list)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A las columnas \"photos\", \"retweet\" y \"url\" las cambiamos por valores de 0 y 1\n",
    "# 0 si no hay photo, url o si el tweet no es retweet\n",
    "# 1 si hay photo, url o si el tweet es retweet\n",
    "\n",
    "df.photos = df.photos.apply(lambda x : 1 if x != \"[]\" else 0)\n",
    "df.retweet = df.retweet.apply(lambda x : 1 if x == \"True\" else 0)\n",
    "df.urls = df.urls.apply(lambda x : 1 if x != \"[]\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Aplica las funciones de limpieza de texto\n",
    "\n",
    "df.tweet = df.tweet.apply(normalize)\n",
    "df.tweet = df.tweet.apply(deEmojify)\n",
    "df.tweet = df.tweet.apply(cleanTxt)\n",
    "df.tweet = df.tweet.apply(replace_punct)\n",
    "df.tweet = df.tweet.apply(replace_num)\n",
    "\n",
    "df.tweet = df.tweet.apply(tokenizador)\n",
    "df.tweet = df.tweet.apply(foo)\n",
    "df.tweet = df.tweet.apply(quita_palabras_pequeñas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas de tiempo\n",
    "\n",
    "df[\"month\"] = df.date.apply(lambda x : x[5 : 7])\n",
    "df[\"day\"] = df.date.apply(lambda x : x[-2:])\n",
    "\n",
    "df[\"hour\"] = df.time.apply(lambda x : x[:2])\n",
    "df[\"minute\"] = df.time.apply(lambda x : x[3:5])\n",
    "df[\"second\"] = df.time.apply(lambda x : x[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas de interaccion:\n",
    "# \"mentions_count\" : cuenta cuantas mentions hay en el tweet\n",
    "# \"reply_to_count\" : cuenta a cuantas personas le hace respuesta el tweet\n",
    "# \"hashtags_count\" : cuenta cuantos hashtags hay en el tweet\n",
    "\n",
    "# \"interaccion\" : es la summa de las 3 columnas anteriores\n",
    "\n",
    "df[\"mentions_count\"] = [len(mention.split(\",\")) if type(mention) == str else 0 for mention in df.mentions]\n",
    "\n",
    "df[\"reply_to_count\"] = [len(reply.split(\",\")) if type(reply) == str else 0 for reply in df.reply_to]\n",
    "\n",
    "df[\"hashtags_count\"] =  [len(hashtag.split(\",\")) if type(hashtag) == str else 0 for hashtag in df.hashtags]\n",
    "\n",
    "df[\"interaccion\"] = [rt + re + lk for rt, re, lk in zip(df.retweets_count, df.replies_count, df.likes_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"tweets_24_tendencia_preprocesado.csv\", sep = \";\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
